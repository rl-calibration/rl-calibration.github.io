<!DOCTYPE html>
<html>
<head>
  <script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>



  <meta charset="utf-8">
  <meta name="description"
        content="Beyond Binary Rewards: RL for Calibrated LMs">
  <meta name="keywords" content="Beyond Binary Rewards: RL for Calibrated LMs">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Beyond Binary Rewards: RL for Calibrated LMs</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>


  <style>
    .scroll-box {
      max-height: 200px;
      overflow-y: auto;
      background-color: #f9f9f9;
      padding: 12px;
      margin: 10px 0;
      border-left: 4px solid #ccc;
      font-family: inherit; /* ‚Üê Uses same font as surrounding text */
      white-space: pre-wrap;
      line-height: 1.5;
    }
  </style>
  


</head>




<body>




<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">

    
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">Beyond Binary Rewards:<br>Training LMs to Reason About Their Uncertainty</h1>
        </div>
      </div>







      <div class="columns" style="align-items: center; margin-left: 0;">
        <div class="column is-narrow" style="padding-right: 20px; margin-left: -10px;">
          <img src="assets/images/logo.png" alt="Logo" style="height: 120px;">
        </div>
        <div class="column" style="padding-left: 0;">
          <div class="is-size-6 publication-authors" style="margin-bottom: 1px;">
            <span class="author-block">
              <a href="https://damanimehul.github.io/">Mehul Damani*</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://ishapuri.github.io/">Isha Puri*</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.stewyslocum.com/">Stewart Slocum</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://idanshen.github.io/">Idan Shenfeld</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=8b8IhUYAAAAJ&hl=en">Leshem Choshen</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://people.csail.mit.edu/yoonkim/">Yoon Kim</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.mit.edu/~jda/">Jacob Andreas</a><sup>1</sup>
            </span>
          </div>
      
          <div class="is-size-6 publication-authors" style="margin-bottom: 1px;">
            <span class="author-block"><sup>*</sup>Equal Contribution,</span>
            <span class="author-block"><sup>1</sup>MIT CSAIL</span>
          </div>
      
          <div class="publication-links">
            <span class="link-block">
              <a href="https://arxiv.org/abs/2507.16806"
                 class="external-link button is-normal" target="_blank" rel="noopener noreferrer">
                <span class="icon"><i class="ai ai-arxiv"></i></span>
                <span>arXiv</span>
              </a>
            </span>
            <span class="link-block">
              <a href="https://github.com/damanimehul/RLCR"
                 class="external-link button is-normal" target="_blank" rel="noopener noreferrer">
                <span class="icon"><i class="fab fa-github"></i></span>
                <span>Code</span>
              </a>
            </span>
            <span class="link-block">
              <a href="https://x.com/MehulDamani2/status/1948069173294481877"
                 class="external-link button is-normal" target="_blank" rel="noopener noreferrer">
                <span class="icon"><i class="fab fa-twitter"></i></span>
                <span>Twitter</span>
              </a>
            </span>
          </div>
        </div>
      </div>
      
      
      






    </div>
  </div>
</section>



<div class="image-container" style="text-align: center; margin: 1px 0;">
  <img src="assets/images/main_fig1.jpg" alt="Main Figure 1" style="max-width: 90%; height: auto;">
</div>















<script src="examples-content.js"></script>




<section class="section">
  <div class="container">
    
    <!-- Gray Question Box -->
    <div id="question-box" class="box" style="background-color: #f5f5f5;">
      <p><strong>Question</strong></p>
      <p id="question-text">Loading...</p>
    </div>

    <div class="columns">
      <!-- Main Viewing Area -->
      <div class="column is-9">
        <div id="viewer-content" class="box" style="min-height: 500px;">
          <!-- Dynamic content inserted here -->
        </div>
      </div>

      <!-- Sidebar Navigation -->
      <div class="column is-3">
        <aside class="menu">
          <p class="menu-label">Examples</p>
          <ul class="menu-list" id="example-list">
            <!-- List items populated by JS -->
          </ul>
        </aside>
      </div>
    </div>
  </div>
</section>

<script>
  // Ensure examples array is available from examples-content.js
  if (typeof examples === 'undefined') {
    console.error("The 'examples' array is not loaded. Make sure examples-content.js is included.");
  } else {
    const questionBox = document.getElementById('question-text');
    const viewerContent = document.getElementById('viewer-content');
    const exampleList = document.getElementById('example-list');

    function loadExample(index) {
      const ex = examples[index];
      questionBox.innerText = ex.question;
      viewerContent.innerHTML = ex.content;

      document.querySelectorAll('.example-link').forEach(link => link.classList.remove('is-active'));
      const activeLink = document.querySelector(`[data-index="${index}"]`);
      if (activeLink) activeLink.classList.add('is-active');
    }

    // Populate sidebar
    examples.forEach((ex, i) => {
      const li = document.createElement('li');
      li.innerHTML = `<a href="#" class="example-link ${i === 0 ? 'is-active' : ''}" data-index="${i}">${ex.title}</a>`;
      exampleList.appendChild(li);
    });

    // Setup listeners
    document.querySelectorAll('.example-link').forEach(link => {
      link.addEventListener('click', (e) => {
        e.preventDefault();
        const index = parseInt(e.target.getAttribute('data-index'));
        loadExample(index);
      });
    });

    // Load first example
    loadExample(0);
  }
</script>













<section id="why-rlcr" class="section" style="font-family: 'DM Sans', sans-serif;">
  <div class="container">
    <div class="box" style="border: 1px solid #ccc; padding: 1.5rem;">
      

      <h2 class="title" style="text-align: center;">Intro</h2>

      <div class="columns">
        <div class="column is-4">
          <div class="content">
            <p>
              Recent advances in reasoning training - particularly <strong>O1-style models</strong> and <strong>RL with verifiable rewards (RLVR)</strong> - have improved the accuracy of large language models (LLMs). These approaches optimize for correctness, encouraging models to output the right answer when possible.
            </p>

            <p>
              However, these same methods tend to produce <strong>overconfident models</strong> that are more prone to <strong>hallucination</strong>. 
              Because the reward signal focuses solely on final answer correctness, models are incentivized to guess‚Äîeven when they are uncertain. 
              This is especially problematic in high-stakes settings like <strong>healthcare</strong> and <strong>law</strong>, where confident errors can be harmful or even dangerous.
            </p>
          </div>
        </div>
        <div class="column is-7">
          <div class="image-container" style="text-align: center; margin: 20px 0;">
            <img src="assets/images/exampleOutputs.jpg" alt="Example Outputs" style="max-width: 100%; height: auto;">
          </div>
        </div>
      </div>

      <div class="content">
        <p>
          <strong>RLCR</strong> addresses this gap. We introduce a reinforcement learning framework that trains models to reason about their own uncertainty‚Äîrewarding not just accuracy, but also calibrated confidence. 
        </p>

        <p>
          Instead of encouraging blind certainty, RLCR incentivizes models to <em>reflect</em>, evaluate their own outputs, and communicate uncertainty when appropriate.
          The result is a model that performs better <strong>(higher accuracy ‚úÖ)</strong> and knows when it's likely to be wrong <strong>(better calibration üéØ)</strong>.
        </p>

        <p>
          In domains where trust, safety, and interpretability matter, this dual optimization‚Äîgetting the right answer, and knowing when you might not‚Äîmakes all the difference.
        </p>
      </div>
    </div>
  </div>
</section>








<section id="our-idea" class="section" style="font-family: 'DM Sans', sans-serif;">
  <div class="container">
    <div class="box" style="border: 1px solid #ccc; padding: 1.5rem;">
      <h2 class="title is-3" style="text-align: center;">Our Idea</h2>

      <div class="content">
        <p><strong>RLCR makes a simple shift:</strong> instead of rewarding only correctness, we reward both accuracy and calibrated confidence.</p>

        <ul>
          <li>üí° <strong>We reward models for being right <em>and</em> for knowing when they're right.</strong></li>
          <li>üí° <strong>We move uncertainty reasoning into training</strong> ‚Äî teaching the model to reflect on its own uncertainty while solving the task.</li>
          <li>üí° <strong>With a simple tweak to the reward function</strong>, RLCR enables LLMs to improve both performance and self-awareness.</li>
        </ul>

        <p>
          During training, the model reasons jointly about the <strong>task</strong> and its own <strong>uncertainty</strong>, 
          producing both an <strong>answer</strong> and a <strong>confidence estimate</strong>.
        </p>

        <p>
          Our reward combines two terms:
        </p>

        <ul>
          <li>üéØ <strong>Correctness</strong> ‚Äî Is the answer right?</li>
          <li>üìè <strong>Calibration</strong> ‚Äî Does the confidence reflect actual correctness?</li>
        </ul>

        <p>
          Confidently wrong or uncertainly right responses are penalized. This encourages models to learn not just what to answer, but how sure to be.
        </p>

        <div class="columns is-centered mt-5">
          <div class="column has-text-centered">
            <img src="assets/images/reward_fns.jpeg" alt="Reward Functions" style="max-width: 100%;">
          </div>
        </div>
        <p>In RLCR, the reward for giving an incorrect answer is never better than the reward for giving a correct answer, which prevents models from losing accuracy.</p>
        <!-- Math Toggle Box -->
        <div class="box" style="border: 1px solid #ccc; padding: 1.5rem;">
          <!-- Tabs -->
          <div class="tabs is-toggle is-toggle-rounded is-centered mb-4">
            <ul>
              <li class="is-active" id="tab-intuitive" onclick="showMath('intuitive')"><a>Intuitive Equation</a></li>
              <li id="tab-symbolic" onclick="showMath('symbolic')"><a>Symbolic Equation</a></li>
            </ul>
          </div>

          <!-- Math Content -->
          <div id="intuitive-math" class="math-view fade-math">
            <p><strong>Traditional RLVR reward:</strong></p>
            <p>$$
            R_{\text{RLVR}} = \text{Correctness} = \mathbb{1}(\text{prediction} = \text{label})
            $$</p>

            <p class="mt-4"><strong>RLCR reward:</strong></p>
            <p>$$
            R_{\text{RLCR}} = \text{Correctness} - \left( \text{Confidence} - \text{Correctness} \right)^2
            $$</p>

            <p>
              where <strong>Correctness</strong> is 1 if the prediction is correct, 0 otherwise; and <strong>Confidence</strong> is the model‚Äôs self-estimated probability that its prediction is correct.
            </p>
          </div>

          <div id="symbolic-math" class="math-view fade-math is-hidden">
            <p><strong>Traditional RLVR reward:</strong></p>
            <p>$$
            R_{\text{RLVR}} = \mathbb{1}(\hat{y} = y)
            $$</p>

            <p class="mt-4"><strong>RLCR reward:</strong></p>
            <p>$$
            R_{\text{RLCR}} = \mathbb{1}(\hat{y} = y) - \left( \hat{p} - \mathbb{1}(\hat{y} = y) \right)^2
            $$</p>

            <p>
              where \( \hat{y} \) is the model‚Äôs prediction, \( y \) is the ground truth, and \( \hat{p} \) is the model‚Äôs confidence estimate.
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- MathJax -->
<script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<!-- Style for fade and tabs -->
<style>
  .fade-math {
    transition: opacity 0.4s ease;
  }
  .is-hidden {
    opacity: 0;
    height: 0;
    overflow: hidden;
    pointer-events: none;
    position: absolute;
  }
  .math-view {
    opacity: 1;
    position: relative;
  }
</style>

<!-- JavaScript Logic -->
<script>
  function showMath(mode) {
    const intuitiveTab = document.getElementById('tab-intuitive');
    const symbolicTab = document.getElementById('tab-symbolic');
    const intuitiveMath = document.getElementById('intuitive-math');
    const symbolicMath = document.getElementById('symbolic-math');

    if (mode === 'intuitive') {
      intuitiveTab.classList.add('is-active');
      symbolicTab.classList.remove('is-active');
      intuitiveMath.classList.remove('is-hidden');
      symbolicMath.classList.add('is-hidden');
    } else {
      symbolicTab.classList.add('is-active');
      intuitiveTab.classList.remove('is-active');
      symbolicMath.classList.remove('is-hidden');
      intuitiveMath.classList.add('is-hidden');
    }

    if (window.MathJax) MathJax.typeset();
  }
</script>























<section id="why-rlcr" class="section" style="font-family: 'DM Sans', sans-serif;">
  <div class="container">
    <div class="box" style="border: 1px solid #ccc; padding: 1.5rem;">
      <h2 class="title is-3 has-text-centered">What We Prove</h2>
      <p> ‚úÖ RLCR provably optimizes for both accuracy & calibration.</p>
      <p> ‚úÖ Calibration comes at no cost to accuracy.</p>
      <p> ‚úÖ Works with any bounded proper scoring rule ‚Äî we use the Brier score.</p>
    </div>
  </div>
</section>

















<section id="results" class="section" style="font-family: 'DM Sans', sans-serif;">
  <div class="container">
    <div class="box" style="border: 1px solid #ccc; padding: 1.5rem;">
      <h2 class="title is-3 has-text-centered">Does it work? Yes! üìä</h2>

      <p>
        On diverse QA & math benchmarks (both in-domain and out-of-distribution):
      </p>

      <ul>
        <li>‚ú® <strong>Accuracy</strong> stays on par (or better) than RL baselines, with <strong>calibration error reduced by up to 90%</strong>.</li>
        <li>‚ú® Outperforms <strong>post-hoc classifiers & probes</strong> on calibration.</li>
        <li>‚ú® <strong>RLVR degrades calibration</strong> in OOD tasks, while <strong>RLCR significantly improves it</strong>.</li>
      </ul>

    <div class="image-container" style="text-align: center; margin: 20px 0;">
        <img src="assets/images/results.jpeg" alt="Results Chart" style="max-width: 100%; height: auto;">
    </div>
    </div>
  </div>
</section>









<section id="test-time-scaling" class="section" style="font-family: 'DM Sans', sans-serif;">
  <div class="container">
    <div class="box has-text-centered" style="border: 1px solid #ccc; padding: 1.5rem;">
      <h2 class="title is-3">Can confidence scores help at test time? üöÄ</h2>

      <p>
        Yes ‚Äî confidence estimates can be directly integrated into <strong>test-time scaling strategies</strong> to improve performance when additional compute is available.
      </p>

      <p>We explore two simple yet effective techniques:</p>
      <ul>
        <li><strong>Max-Confidence Selection</strong>: Choose the response with the highest self-reported confidence.</li>
        <li><strong>Confidence-Weighted Majority Voting</strong>: Aggregate multiple responses, weighting each vote by its confidence score.</li>
      </ul>

      <p>
        These strategies yield <strong>better accuracy and calibration</strong> as compute scales. üìà
      </p>

    <div class="image-container" style="text-align: center; margin: 20px 0;">
        <img src="assets/images/inf_scaling.png" alt="Inference Scaling Strategies" style="max-width: 100%; height: auto;">
    </div>
    </div>
  </div>
</section>






<section id="uncertainty-cot" class="section" style="font-family: 'DM Sans', sans-serif;">
  <div class="container">
    <div class="box" style="border: 1px solid #ccc; padding: 1.5rem;">
      <h2 class="title is-3 has-text-centered">Does Explicitly Reasoning About Uncertainty Help? üß†</h2>

      <p>
        To investigate the impact of uncertainty reasoning within the chain-of-thought (CoT), we trained two types of classifiers:
      </p>
      <br>
      <li><strong>Baseline:</strong> Trained on model solutions and final answers.</li>
      <li><strong>Analysis:</strong> Trained on the same, but with explicit uncertainty reasoning included in the CoT.</li>
      
      <br>
      <p>
        <strong>Result:</strong> The analysis classifier <strong>outperformed</strong> the baseline, particularly for <strong>smaller model sizes</strong>.  
        Larger models can infer confidence from solutions alone, but smaller ones benefit from having uncertainty reasoning made explicit.
      </p>

      <br>
      <p>
        üîç <strong>Classifier capacity shapes the optimal CoT content</strong> ‚Äî a key insight for future work in prompting and model alignment.
      </p>

      <div class="image-container" style="text-align: center; margin: 20px 0;">
        <img src="assets/images/classifier.png" alt="Classifier Results" style="max-width: 100%; height: auto;">
    </div>

    </div>
  </div>
</section>








<section class="section" id="BibTeX" style="font-family: 'DM Sans', sans-serif;">
  <div class="container is-max-desktop content">
    <h2 class="title" style="text-align: center;">BibTeX</h2>
    <pre style="background-color: #bbb9b98b; padding: 15px; border-radius: 5px;"><code>@misc{damani2025binaryrewardstraininglms,
  title={Beyond Binary Rewards: Training LMs to Reason About Their Uncertainty},
  author={Mehul Damani and Isha Puri and Stewart Slocum and Idan Shenfeld and Leshem Choshen and Yoon Kim and Jacob Andreas},
  year={2025},
  eprint={2507.16806},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2507.16806},
}</code></pre>
  </div>
</section>

</body>
</html>
